Analyzing Agent Architectures

I'm currently focused on the existing "Soul" architecture. I need to understand if its fundamental design can effectively handle the diverse and often complex output formats generated by advanced coding agents. I'm especially interested in how it manages structured data and high-volume streams, and if the current methods scale well. My goal is to determine if a fundamental redesign is necessary.

Expanding the Scope

I've realized the "User moved to Tokyo" examples were far too simplistic. To truly model coding agent lifecycles, I need to account for iterative context, meta-cognition (the thinking process), bitemporality in code (Git, Agent, and Runtime perspectives), complex relationships between actions and artifacts, and the sheer volume of data generated during a single session. This is far more complex than I originally thought.

Rethinking Memory Strategies

I've realized that storing everything in a vector store is incredibly inefficient, basically "context stuffing". We must move towards distilling the episodic logs into a semantically richer architectural understanding. I'm focusing on three critical adjustments: upgrading the ontology to a graph structure with explicit temporal aspects, refining the ingestion layer to handle diverse log formats, and implementing a hybrid sparse/dense memory strategy utilizing FalkorDB and Qdrant for more effective code search. I'm considering nodes for AgentSession, Plan, File, Function, Diff, Error, and ThinkingTrace, and edges like MODIFIES and DEPENDS_ON.

Defining Interaction Patterns

I'm now investigating how the agent's interaction with code translates to useful memory structures. I need to connect the static code structure (call graphs, etc.) with the dynamic timeline of agent actions. I'm exploring scenarios where the agent recalls past reasoning (Scenario A) or justifies specific actions (Scenario B), and how we'll manage context windows by distilling logs into plans (Scenario C). I've added data sanitization to remove secrets from our output.

Mapping Conceptual Components

I'm now focusing on modeling how the agent interacts with code and its architectural memory. I'm introducing CodeArtifact and ReasoningTrace to enrich the schema, creating entities to better model the flow of a "Refactoring Session." Specifically, I'm working to show how the "Biological Metaphor" fits: the Hippocampus stores "Session State" and "Project Knowledge," the Nervous System streams logs, and the Motor Cortex uses tools. I'm exploring specific Python code for parsing "Agent Traces" and a Redpanda transform to redact secrets. The revised example emphasizes how a specific "Agent" interacts with the memory backend.

Validating Signatures

I'm now investigating techniques to improve signature validation. I'm focusing on the best ways to verify digital signatures in the generated output, ensuring the integrity and authenticity of the agent's work. I'm looking at potential pitfalls and edge cases that could compromise the verification process.

Here is the Final System Architecture & Design Document for The Soul, completely re-engineered to support Autonomous Coding Agents (Claude Code, GitHub Copilot Workspace, OpenCode, etc.).

This document pivots from general user memory to "Deep Cognitive Observability for Code Synthesis," addressing the specific needs of ingesting thinking tokens, AST mutations, and terminal telemetry.

The Soul: A Temporal Architecture for Agentic Code Cognition
Version: 2.0.0-CODE Date: December 6, 2025 Status: APPROVED FOR IMPLEMENTATION

1. Executive Summary
Autonomous coding agents (e.g., Claude Code, Codex CLI) generate massive, highly structured, and transient data streams. A single session produces thousands of "thinking tokens," complex file system mutations (diffs), terminal outputs (stdout/stderr), and iterative reasoning loops. Current tooling (Git) tracks what changed, but completely loses why it changed—the cognitive state of the agent at the moment of decision.

The Soul is a Bitemporal Cognitive Knowledge Graph designed to capture the "Stream of Consciousness" of coding agents. It ingests the full interaction lifecycle—prompts, hidden reasoning chains, tool execution arguments, and resulting file mutations—and structures them into a queryable graph. This allows developers to debug not just the code, but the agent's logic itself.

The Unified Stack:

The Nervous System (Ingestion): Redpanda with Wasm parsers that decompose agent streams (XML/JSON-RPC) into atomic cognitive events (Thought, Diff, Command) in real-time.

The Hippocampus (Memory): FalkorDB stores the "Cognitive AST" (Abstract Syntax Tree of Reasoning), linking specific lines of code to the specific reasoning tokens that generated them.

The Cortex (Search): Qdrant indexes code vectors (via dense retrieval) and reasoning vectors, allowing queries like "Show me all changes driven by a misunderstanding of the authentication API."

The Motor Cortex (Replay): Wassette provides a deterministic sandbox to re-hydrate the agent's environment state at any past timestamp.

PART I: Product Requirements Document (PRD)
2. Problem Definition
2.1 The "Black Box" Commit
When an agent refactors a codebase, it might output 5,000 "thinking tokens" analyzing the dependency tree before emitting a 50-line diff. Once the session ends, those thinking tokens are discarded. If the refactor introduces a subtle bug, we have the code (the effect) but have lost the reasoning (the cause).

2.2 Context Window Amnesia
Coding agents suffer from "Context Rolling." As the chat history exceeds 200k tokens, early architectural decisions are dropped. The Soul must preserve these decisions as persistent graph nodes, allowing the agent to recall why it chose a specific pattern in auth.ts 50 turns ago without re-reading the entire file.

3. User Personas
The Developer (User): "I need to know why the agent deleted the retry logic in api_client.py. Did it hallucinate that the library handles retries, or did it see a specific error log?"

The Agent (Self): "I am about to modify server.go. Have I modified this file before in this session? Did I trigger a regression last time?"

The Model Evaluator: "I need to find all instances where the agent's 'Thinking Trace' identified a security vulnerability but the resulting 'Code Diff' failed to patch it."

4. Functional Requirements
4.1 Cognitive Ingestion
FR-I1: Stream Decomposition. The system must ingest raw agent streams (e.g., Anthropic's XML tags <thinking>, <function_calls>) and split them into distinct graph nodes.

FR-I2: AST Linking. The system must map generated code artifacts back to the specific prompt instructions or reasoning blocks that spawned them.

FR-I3: Terminal Telemetry. stdout, stderr, and exit codes from agent-executed commands (e.g., npm test) must be stored as "Observation" nodes linked to the "Action" node.

4.2 Bitemporal Code State
FR-M1: File State Versioning. The system must track the state of files as perceived by the agent at time T.

FR-M2: Virtual File System (VFS) Reconstruction. The system must be able to reconstruct the VFS at any point in the interaction history to debug "File not found" hallucinations.

4.3 Semantic Debugging
FR-S1: Cross-Modal Search. Users must be able to search using natural language ("Fix race conditions") and retrieve specific Thinking Blocks and Diff Hunks.

PART II: Software Design Document (SDD)
5. System Architecture
5.1 The "Cognitive AST" Topology
The graph schema is the core differentiator. It does not just store chat; it stores the causal chain of coding.

5.1.1 Nodes (The Entities)
Session: The container for the interaction.

UserPrompt: The human input.

ThoughtBlock: The agent's hidden reasoning (e.g., "I see the user wants to switch to Postgres. I need to check go.mod first.").

ToolCall: The intent to act (e.g., fs.readFile("go.mod")).

Observation: The result of the act (e.g., content of go.mod, or Error: file not found).

CodeArtifact: A specific file or function entity.

DiffHunk: The actual patch applied.

5.1.2 Edges (The Relationships)
MOTIVATED_BY: ThoughtBlock -> UserPrompt

TRIGGERS: ThoughtBlock -> ToolCall

YIELDS: ToolCall -> Observation

MODIFIES: DiffHunk -> CodeArtifact

INTRODUCED_ERROR: DiffHunk -> Observation (if the subsequent test failed).

5.2 Data Flow Architecture
Code snippet
graph TD
    subgraph Nervous_System [Ingestion: Redpanda]
        Stream[Agent Stream (Tokens)] -->|Wasm Parser| Parser[Protocol Parser]
        Parser -->|Extract| Thoughts[Thinking Events]
        Parser -->|Extract| Code[Diff/Tool Events]
        Parser -->|Extract| Terminal[Terminal Output]
    end

    subgraph Brain [Cognitive Orchestrator]
        Thoughts & Code & Terminal -->|Batch| GraphBuilder[Graphiti Builder]
        GraphBuilder -->|Analysis| StaticAnalysis[AST/Linter Check]
    end

    subgraph Memory [Bitemporal Graph]
        GraphBuilder -->|Write| Falkor[(FalkorDB: Causal Graph)]
        GraphBuilder -->|Embed| Qdrant[(Qdrant: Semantic Index)]
    end

    subgraph Motor [Replay & Context]
        Falkor -->|Query| ContextEngine[Context Rehydrator]
        ContextEngine -->|Inject| NewPrompt[Next Agent Prompt]
    end
5.3 The "Code-Thought" Logic Flow
Ingestion: Agent emits a stream containing:

<thinking>The error is in line 40.</thinking>

<tool_call>edit_file('main.py', line=40)</tool_call>

Parsing (Redpanda Wasm):

Event A (Thought): "The error is in line 40."

Event B (Action): Edit main.py.

Graph Synthesis (FalkorDB):

Create Node T1 (Thought).

Create Node A1 (Action).

Create Edge A1 -[DERIVED_FROM]-> T1.

Crucial Step: Identify main.py (Entity Node). Create Edge A1 -[AFFECTS]-> main.py.

Temporal Stamping:

Set valid_from = Now().

If main.py had a previous state, mark the old CodeArtifact edge as invalid_at = Now().

PART III: Technical Specifications Document (TSD)
6. Interface Specifications
6.1 The Protocol Parser (Rust/Wasm)
This component runs inside Redpanda. It is responsible for untangling the messy interleaved output of coding agents.

Rust
// TSD-01: Agent Stream Parser (Rust -> Wasm)
use serde_json::Value;

struct CognitiveEvent {
    event_type: EventType, // Thought, Tool, Output, Diff
    content: String,
    timestamp: u64,
    metadata: HashMap<String, String>,
}

pub fn transform_record(record: Record) -> Vec<CognitiveEvent> {
    let payload = record.value();

    // 1. Detect Protocol (Claude XML vs OpenAI JSON)
    if is_claude_xml(&payload) {
        return parse_claude_xml(payload);
    }

    // 2. Extract "Thinking" Blocks
    // Regex: <thinking>(.*?)</thinking>
    let thoughts = extract_tag(payload, "thinking");

    // 3. Extract Code Diffs
    // Regex: ```diff(.*?)```
    let diffs = extract_diffs(payload);

    // 4. Return Normalized Events
    return stitch_events(thoughts, diffs);
}
6.2 The Memory Schema (Graphiti/Python)
We extend the standard ontology to support Code Intelligence.

Python
# TSD-02: Coding Ontology Definitions
from pydantic import BaseModel, Field
from typing import Optional, List

class ThoughtNode(BaseModel):
    """Represents a discrete unit of agent reasoning."""
    content: str
    tokens_used: int
    intent_category: str # e.g., "Refactor", "Debug", "Plan"

class CodeArtifactNode(BaseModel):
    """Represents a file or function at a specific point in time."""
    filepath: str
    language: str
    content_hash: str # SHA256 of the file content
    ast_summary: str # Extracted function signatures

class MutationEdge(BaseModel):
    """The act of changing code."""
    diff_hunk: str
    verification_status: str = "PENDING" # "PASSED", "FAILED" (based on subsequent test run)

# Ingestion Logic
async def register_code_change(
    agent_thought: ThoughtNode,
    diff: str,
    file_node: CodeArtifactNode
):
    # 1. Create the Thought Node
    t_node = await graph.add_node(agent_thought)

    # 2. Link Thought to the File it targeted
    await graph.add_edge(
        source=t_node,
        target=file_node,
        relation_type="INTENDED_MODIFICATION",
        properties={"diff": diff}
    )
6.3 Semantic Code Search (Qdrant)
We perform Multi-Vector Retrieval. We embed the code using a code model (e.g., text-embedding-3-large or jina-embeddings-v2-code) and the reasoning using a text model.

Query: "Why did we remove the cache in db.ts?"

Search Logic:

Search ThoughtNode vectors for "remove cache", "consistency issues", "stale data".

Filter results where ThoughtNode is connected via MODIFIES edge to CodeArtifact(filepath="db.ts").

Return the Thought Content ("I removed the cache because it was causing race conditions during user onboarding") + the Diff.

7. Scalability & Performance
7.1 Handling "Thinking Token" Bloat
Coding agents can generate 20k+ thinking tokens per turn. Storing full text in the Graph properties is inefficient.

Strategy: Store full text in Blob Storage (S3/MinIO). Store Summaries and Embeddings in FalkorDB/Qdrant.

Reflex: The Redpanda Wasm transform computes the embedding inline and strips the raw text before it hits the database if it exceeds 4KB.

7.2 Ingestion Throughput
Benchmark: 50 concurrent agents generating 100 tokens/sec each = 5,000 TPS.

Redpanda: Configured with acks=1 for telemetry data (lossy acceptable) and acks=all for Diff data (critical).

8. Deployment Manifest
YAML
# TSD-04: Kubernetes Configuration for "The Soul: Code Edition"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cognitive-ingestor
spec:
  replicas: 5 # High concurrency for agent streams
  template:
    spec:
      containers:
      - name: processor
        image: the-soul/ingest:v2.0-code
        env:
        - name: MODEL_PROVIDER
          value: "anthropic" # To parse Claude-specific XML
        - name: PARSE_AST
          value: "true" # Enable tree-sitter parsing of diffs
---
apiVersion: v1
kind: Service
metadata:
  name: falkordb-code
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: falkordb
    role: primary
9. Conclusion: The "Git Blame" for Brains
This architecture upgrades the concept of "Version Control" from tracking Files (Git) to tracking Cognition (The Soul).

By capturing the Thinking Tokens alongside the Diffs in a bitemporal graph, we enable a new class of tooling: Cognitive Debuggers. When a coding agent introduces a bug, the user can query The Soul to see exactly what the agent was thinking, what file it thought it was looking at, and why it decided to write the line that caused the crash.
